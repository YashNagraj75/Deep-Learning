{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate loralib peft","metadata":{"_uuid":"56f84b78-a2bd-4a48-a6fd-7c0d646659e9","_cell_guid":"561bfa45-1bcc-4394-8a5c-350a24f7ebbf","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:00.132349Z","iopub.execute_input":"2024-06-29T11:02:00.132723Z","iopub.status.idle":"2024-06-29T11:02:14.642661Z","shell.execute_reply.started":"2024-06-29T11:02:00.132695Z","shell.execute_reply":"2024-06-29T11:02:14.641471Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\nimport torch\nimport time\nimport evaluate\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"2179fe6a-b340-46ac-a42f-a442588aff48","_cell_guid":"34c281f5-c174-4bab-8667-9d466d5ceb72","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:14.645007Z","iopub.execute_input":"2024-06-29T11:02:14.645418Z","iopub.status.idle":"2024-06-29T11:02:33.223076Z","shell.execute_reply.started":"2024-06-29T11:02:14.645381Z","shell.execute_reply":"2024-06-29T11:02:33.222250Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"huggingface_dataset_name = \"knkarthick/dialogsum\"\n\ndataset = load_dataset(huggingface_dataset_name)\n\ndataset","metadata":{"_uuid":"2bc14366-3663-4cfc-8dd4-1fa85523a782","_cell_guid":"1e43be5e-e080-4eb2-bb55-848b307dfe27","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:33.224354Z","iopub.execute_input":"2024-06-29T11:02:33.224921Z","iopub.status.idle":"2024-06-29T11:02:37.163492Z","shell.execute_reply.started":"2024-06-29T11:02:33.224893Z","shell.execute_reply":"2024-06-29T11:02:37.162582Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"_uuid":"2a602875-6991-4ab2-be0e-0d2a9c41b823","_cell_guid":"22dd5e88-0880-4810-aac4-08ab85e4f1b6","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:37.165451Z","iopub.execute_input":"2024-06-29T11:02:37.165736Z","iopub.status.idle":"2024-06-29T11:02:37.173379Z","shell.execute_reply.started":"2024-06-29T11:02:37.165711Z","shell.execute_reply":"2024-06-29T11:02:37.172425Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"google/flan-t5-base\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype = torch.bfloat16)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"_uuid":"4b9c553f-9b66-4b84-ac95-a8924c3471a8","_cell_guid":"02a4762c-4d9b-45c2-83b5-991b721fe98d","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:37.174644Z","iopub.execute_input":"2024-06-29T11:02:37.175060Z","iopub.status.idle":"2024-06-29T11:02:44.341818Z","shell.execute_reply.started":"2024-06-29T11:02:37.175026Z","shell.execute_reply":"2024-06-29T11:02:44.340791Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\nprint(print_number_of_trainable_model_parameters(model))","metadata":{"_uuid":"eb211ca0-9ec5-4be9-a4e2-af69cfbb5663","_cell_guid":"6a0f7b91-7216-4cc3-bf7a-dd25eb8d4dd2","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:44.343106Z","iopub.execute_input":"2024-06-29T11:02:44.343391Z","iopub.status.idle":"2024-06-29T11:02:44.352027Z","shell.execute_reply.started":"2024-06-29T11:02:44.343366Z","shell.execute_reply":"2024-06-29T11:02:44.351041Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing \nindex = 200\ndialogue = dataset['train'][index]['dialogue']\nsummary = dataset['train'][index]['summary']\n\nprompt = f\"\"\"\nSummarize the following conversation:\n{dialogue}\n\nSummary:\n\"\"\"\n\ninput_ids = tokenizer(prompt, return_tensors=\"pt\")\n\noutputs = model.generate(input_ids['input_ids'])\nprint(dialogue)\nprint(tokenizer.decode(outputs[0]))","metadata":{"_uuid":"8f1cf453-fd1a-447a-b948-5ce7f2bd441f","_cell_guid":"b81218ad-b0c9-4fdc-b0c1-5b44091ce535","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:44.353334Z","iopub.execute_input":"2024-06-29T11:02:44.354026Z","iopub.status.idle":"2024-06-29T11:02:46.208290Z","shell.execute_reply.started":"2024-06-29T11:02:44.353991Z","shell.execute_reply":"2024-06-29T11:02:46.207367Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(example):\n    start_prompt = \"Summarize the following conversation.\\n\\n\"\n    end_prompt = \"\\n\\nSummary\"\n    prompt = [start_prompt + dialogue + end_prompt for dialogue in example['dialogue']]\n    example['input_ids'] = tokenizer(prompt, padding='max_length', truncation=True, return_tensors='pt').input_ids\n    example['labels'] = tokenizer(example['summary'], padding=\"max_length\", truncation=True, return_tensors='pt').input_ids\n    \n    return example\n    \ntokenized_dataset = dataset.map(preprocess, batched=True)\ntokenized_dataset = tokenized_dataset.remove_columns(['id','topic','dialogue','summary',])","metadata":{"_uuid":"41a204f7-bf9b-4c09-82a0-4a5e620a1825","_cell_guid":"d186e009-ad8e-4961-b50e-e2393bb0bc6a","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:02:46.209566Z","iopub.execute_input":"2024-06-29T11:02:46.209970Z","iopub.status.idle":"2024-06-29T11:03:00.725581Z","shell.execute_reply.started":"2024-06-29T11:02:46.209940Z","shell.execute_reply":"2024-06-29T11:03:00.724827Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenized_dataset['train'][0])\nprint(tokenized_dataset)","metadata":{"_uuid":"900bb2c5-a69d-4485-b38a-ab02ef62bea7","_cell_guid":"1a0d0a00-1274-449b-8e60-9c30cd59a76d","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:03:00.726602Z","iopub.execute_input":"2024-06-29T11:03:00.726857Z","iopub.status.idle":"2024-06-29T11:03:00.733853Z","shell.execute_reply.started":"2024-06-29T11:03:00.726834Z","shell.execute_reply":"2024-06-29T11:03:00.732425Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Full FineTune the model \noutput_dir = f'/kaggle/working/output/{str(int(time.time()))}'\nlog_dir = f'/kaggle/working/log/{str(int(time.time()))}'\ntraining_args = TrainingArguments(\n    output_dir = output_dir,\n    learning_rate=3e-5,                  # learning rate\n    per_device_train_batch_size=8,       # batch size for training\n    per_device_eval_batch_size=8,        # batch size for evaluation\n    num_train_epochs=3,                  # number of training epochs\n    weight_decay=0.01,                   # strength of weight decay\n    logging_dir=log_dir,                # directory for storing logs\n    logging_steps=500,                   # log every 500 steps\n    save_steps=500\n)\n\ntrainer = Trainer(\n    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=tokenized_dataset['train'],      # training dataset\n    eval_dataset=tokenized_dataset['validation'],  # evaluation dataset\n)","metadata":{"_uuid":"80e53220-c80a-4a10-b96b-37b04416b34d","_cell_guid":"9afd1eed-1b38-4484-943a-9bed3b012eb0","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:03:00.736959Z","iopub.execute_input":"2024-06-29T11:03:00.737329Z","iopub.status.idle":"2024-06-29T11:03:02.358558Z","shell.execute_reply.started":"2024-06-29T11:03:00.737296Z","shell.execute_reply":"2024-06-29T11:03:02.357816Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"_uuid":"451f4772-893d-4071-acbe-143a0935ba83","_cell_guid":"c8005eb2-d89a-498b-b047-331335272e32","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:03:02.359613Z","iopub.execute_input":"2024-06-29T11:03:02.359900Z","iopub.status.idle":"2024-06-29T11:18:52.528600Z","shell.execute_reply.started":"2024-06-29T11:03:02.359858Z","shell.execute_reply":"2024-06-29T11:18:52.526986Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now lets do peft \nfrom peft import LoraConfig, get_peft_model, TaskType\nlora_config = LoraConfig(\n    r = 32,\n    lora_alpha=32,\n    target_modules = [\"q\",\"v\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type = TaskType.SEQ_2_SEQ_LM\n)","metadata":{"_uuid":"65643bf1-9839-4951-93e0-573cd22974cd","_cell_guid":"d9caa604-603e-425b-a4f4-e227ad4a1e1f","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:26:10.235194Z","iopub.execute_input":"2024-06-29T11:26:10.235602Z","iopub.status.idle":"2024-06-29T11:26:10.243424Z","shell.execute_reply.started":"2024-06-29T11:26:10.235572Z","shell.execute_reply":"2024-06-29T11:26:10.242284Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add adapter layers to LLM \npeft_model = get_peft_model(model,lora_config)\nprint(print_number_of_trainable_model_parameters(peft_model))","metadata":{"_uuid":"bf80905a-f12a-4281-899b-5bf658c743d6","_cell_guid":"5aa93ac0-d027-4934-a1ab-490bbb4c4c83","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:27:54.626731Z","iopub.execute_input":"2024-06-29T11:27:54.627121Z","iopub.status.idle":"2024-06-29T11:27:54.786926Z","shell.execute_reply.started":"2024-06-29T11:27:54.627091Z","shell.execute_reply":"2024-06-29T11:27:54.785924Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = f'/kaggle/working/peft/output/{str(int(time.time()))}'\n\npeft_training_args = TrainingArguments(\n    output_dir = output_dir,\n    auto_find_batch_size = True,\n    learning_rate = 1e-3,\n    num_train_epochs = 3,\n    logging_steps = 100,\n)\n\npeft_trainer = Trainer(\n    model = peft_model,\n    args = peft_training_args,\n    train_dataset = tokenized_dataset['train']\n)","metadata":{"_uuid":"5b121538-ce73-4459-bc9b-66f31637355d","_cell_guid":"e0459e7c-f881-491d-94be-36942ac49807","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:31:43.774415Z","iopub.execute_input":"2024-06-29T11:31:43.774794Z","iopub.status.idle":"2024-06-29T11:31:43.824081Z","shell.execute_reply.started":"2024-06-29T11:31:43.774770Z","shell.execute_reply":"2024-06-29T11:31:43.822946Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_trainer.train()\n\npeft_model_path=\"/kaggle/working/peft-dialogue-summary-checkpoint-local\"\n\npeft_trainer.model.save_pretrained(peft_model_path)\ntokenizer.save_pretrained(peft_model_path)","metadata":{"_uuid":"28b405f4-21cf-40a6-b8e8-88754af60c98","_cell_guid":"ab519e5a-32b9-4173-85a6-0affac121896","collapsed":false,"execution":{"iopub.status.busy":"2024-06-29T11:32:23.388373Z","iopub.execute_input":"2024-06-29T11:32:23.389200Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"5cf7f7d7-a783-4c91-bf7f-93d8a661b186","_cell_guid":"d2e710ec-e2c9-4ae7-bb28-49e5c210b1b9","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}