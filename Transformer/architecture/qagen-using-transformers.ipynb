{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8698659,"sourceType":"datasetVersion","datasetId":5216945}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import datasets","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:10.774167Z","iopub.execute_input":"2024-06-16T06:14:10.774549Z","iopub.status.idle":"2024-06-16T06:14:10.780524Z","shell.execute_reply.started":"2024-06-16T06:14:10.774519Z","shell.execute_reply":"2024-06-16T06:14:10.779716Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"facebook/babi_qa\",'en-10k-qa1')\nprint(dataset['train'][0])","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:10.944312Z","iopub.execute_input":"2024-06-16T06:14:10.944947Z","iopub.status.idle":"2024-06-16T06:14:13.528326Z","shell.execute_reply.started":"2024-06-16T06:14:10.944915Z","shell.execute_reply":"2024-06-16T06:14:13.527460Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/51.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5229fde1843b4bb0a26b6d970a16c405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/9.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f6b397f94ab4e2aa32adf5b0ee0b3c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cd4d442e41e431fa9f2e4d6363a22f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e28a0d1df474def883608b75808aabf"}},"metadata":{}},{"name":"stdout","text":"{'story': {'id': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15'], 'type': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1], 'text': ['Mary moved to the bathroom.', 'John went to the hallway.', 'Where is Mary?', 'Daniel went back to the hallway.', 'Sandra moved to the garden.', 'Where is Daniel?', 'John moved to the office.', 'Sandra journeyed to the bathroom.', 'Where is Daniel?', 'Mary moved to the hallway.', 'Daniel travelled to the office.', 'Where is Daniel?', 'John went back to the garden.', 'John moved to the bedroom.', 'Where is Sandra?'], 'supporting_ids': [[], [], ['1'], [], [], ['4'], [], [], ['4'], [], [], ['11'], [], [], ['8']], 'answer': ['', '', 'bathroom', '', '', 'hallway', '', '', 'hallway', '', '', 'office', '', '', 'bathroom']}}\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset['train'][102]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:13.530273Z","iopub.execute_input":"2024-06-16T06:14:13.530704Z","iopub.status.idle":"2024-06-16T06:14:13.541149Z","shell.execute_reply.started":"2024-06-16T06:14:13.530671Z","shell.execute_reply":"2024-06-16T06:14:13.540081Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'story': {'id': ['1',\n   '2',\n   '3',\n   '4',\n   '5',\n   '6',\n   '7',\n   '8',\n   '9',\n   '10',\n   '11',\n   '12',\n   '13',\n   '14',\n   '15'],\n  'type': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n  'text': ['Sandra journeyed to the hallway.',\n   'Mary travelled to the bathroom.',\n   'Where is Mary?',\n   'John moved to the office.',\n   'Mary moved to the bedroom.',\n   'Where is Mary?',\n   'Mary journeyed to the kitchen.',\n   'Mary went back to the bathroom.',\n   'Where is John?',\n   'John moved to the bathroom.',\n   'Mary went back to the kitchen.',\n   'Where is Mary?',\n   'Sandra journeyed to the bedroom.',\n   'Daniel went back to the kitchen.',\n   'Where is John?'],\n  'supporting_ids': [[],\n   [],\n   ['2'],\n   [],\n   [],\n   ['5'],\n   [],\n   [],\n   ['4'],\n   [],\n   [],\n   ['11'],\n   [],\n   [],\n   ['10']],\n  'answer': ['',\n   '',\n   'bathroom',\n   '',\n   '',\n   'bedroom',\n   '',\n   '',\n   'office',\n   '',\n   '',\n   'kitchen',\n   '',\n   '',\n   'bathroom']}}"},"metadata":{}}]},{"cell_type":"code","source":"type_set = set()\nfor story in dataset['train']:\n    if str(story['story']['type'] )not in type_set:\n        type_set.add(str(story['story']['type'] ))\ntype_set","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:13.542485Z","iopub.execute_input":"2024-06-16T06:14:13.542807Z","iopub.status.idle":"2024-06-16T06:14:13.896827Z","shell.execute_reply.started":"2024-06-16T06:14:13.542778Z","shell.execute_reply":"2024-06-16T06:14:13.895992Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'[0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]'}"},"metadata":{}}]},{"cell_type":"code","source":"flatten_dataset = dataset.flatten()\nflatten_dataset","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:13.899179Z","iopub.execute_input":"2024-06-16T06:14:13.899455Z","iopub.status.idle":"2024-06-16T06:14:13.912620Z","shell.execute_reply.started":"2024-06-16T06:14:13.899429Z","shell.execute_reply":"2024-06-16T06:14:13.911777Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['story.id', 'story.type', 'story.text', 'story.supporting_ids', 'story.answer'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['story.id', 'story.type', 'story.text', 'story.supporting_ids', 'story.answer'],\n        num_rows: 200\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"next(iter(flatten_dataset['train']))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:13.913779Z","iopub.execute_input":"2024-06-16T06:14:13.914038Z","iopub.status.idle":"2024-06-16T06:14:13.922356Z","shell.execute_reply.started":"2024-06-16T06:14:13.914017Z","shell.execute_reply":"2024-06-16T06:14:13.921598Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'story.id': ['1',\n  '2',\n  '3',\n  '4',\n  '5',\n  '6',\n  '7',\n  '8',\n  '9',\n  '10',\n  '11',\n  '12',\n  '13',\n  '14',\n  '15'],\n 'story.type': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n 'story.text': ['Mary moved to the bathroom.',\n  'John went to the hallway.',\n  'Where is Mary?',\n  'Daniel went back to the hallway.',\n  'Sandra moved to the garden.',\n  'Where is Daniel?',\n  'John moved to the office.',\n  'Sandra journeyed to the bathroom.',\n  'Where is Daniel?',\n  'Mary moved to the hallway.',\n  'Daniel travelled to the office.',\n  'Where is Daniel?',\n  'John went back to the garden.',\n  'John moved to the bedroom.',\n  'Where is Sandra?'],\n 'story.supporting_ids': [[],\n  [],\n  ['1'],\n  [],\n  [],\n  ['4'],\n  [],\n  [],\n  ['4'],\n  [],\n  [],\n  ['11'],\n  [],\n  [],\n  ['8']],\n 'story.answer': ['',\n  '',\n  'bathroom',\n  '',\n  '',\n  'hallway',\n  '',\n  '',\n  'hallway',\n  '',\n  '',\n  'office',\n  '',\n  '',\n  'bathroom']}"},"metadata":{}}]},{"cell_type":"code","source":"# Now we extract the question, answers and sentences from the dataset\ndef get_question_and_facts(story):\n    dic ={}\n    dic['question'] = story['story.text'][2::3]\n    dic['answer'] = [ans for ans in story['story.answer'] if ans]\n    sentences = ' '.join([sen for sen in story['story.text'] if not sen.endswith('?')])\n    assert isinstance(sentences, str), \"Sentences should be a string\"\n    dic['sentences'] = str(sentences)\n    return dic","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:13.923447Z","iopub.execute_input":"2024-06-16T06:14:13.923839Z","iopub.status.idle":"2024-06-16T06:14:13.931624Z","shell.execute_reply.started":"2024-06-16T06:14:13.923810Z","shell.execute_reply":"2024-06-16T06:14:13.930863Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"processed = flatten_dataset.map(get_question_and_facts)\nprocessed['train'][3]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:13.932522Z","iopub.execute_input":"2024-06-16T06:14:13.932746Z","iopub.status.idle":"2024-06-16T06:14:14.375437Z","shell.execute_reply.started":"2024-06-16T06:14:13.932727Z","shell.execute_reply":"2024-06-16T06:14:14.374589Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34da3f51c1d748f389ddc0918f753a74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee1d1396a9084390a7f03dbeda5e2b4f"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'story.id': ['1',\n  '2',\n  '3',\n  '4',\n  '5',\n  '6',\n  '7',\n  '8',\n  '9',\n  '10',\n  '11',\n  '12',\n  '13',\n  '14',\n  '15'],\n 'story.type': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n 'story.text': ['Daniel journeyed to the kitchen.',\n  'Daniel journeyed to the bedroom.',\n  'Where is Daniel?',\n  'Sandra moved to the garden.',\n  'Sandra went back to the kitchen.',\n  'Where is Sandra?',\n  'Daniel travelled to the office.',\n  'Sandra went back to the hallway.',\n  'Where is Sandra?',\n  'Daniel journeyed to the hallway.',\n  'Daniel went to the bathroom.',\n  'Where is Sandra?',\n  'John travelled to the garden.',\n  'Daniel moved to the hallway.',\n  'Where is Daniel?'],\n 'story.supporting_ids': [[],\n  [],\n  ['2'],\n  [],\n  [],\n  ['5'],\n  [],\n  [],\n  ['8'],\n  [],\n  [],\n  ['8'],\n  [],\n  [],\n  ['14']],\n 'story.answer': ['',\n  '',\n  'bedroom',\n  '',\n  '',\n  'kitchen',\n  '',\n  '',\n  'hallway',\n  '',\n  '',\n  'hallway',\n  '',\n  '',\n  'hallway'],\n 'question': ['Where is Daniel?',\n  'Where is Sandra?',\n  'Where is Sandra?',\n  'Where is Sandra?',\n  'Where is Daniel?'],\n 'answer': ['bedroom', 'kitchen', 'hallway', 'hallway', 'hallway'],\n 'sentences': 'Daniel journeyed to the kitchen. Daniel journeyed to the bedroom. Sandra moved to the garden. Sandra went back to the kitchen. Daniel travelled to the office. Sandra went back to the hallway. Daniel journeyed to the hallway. Daniel went to the bathroom. John travelled to the garden. Daniel moved to the hallway.'}"},"metadata":{}}]},{"cell_type":"code","source":"# Now we need the start and end indexes of the answer in the sentences\nstory = processed['train'][3]\ndef get_indexes(story):\n    starts = []\n    ends = []\n    indexes = [int(idx) for sid in story['story.supporting_ids'] for idx in sid]\n    \n    i=0\n    for idx in indexes:\n        if i > len(indexes):\n            break\n        start = story['story.text'][idx-1].find(story['answer'][i])\n        end = start + len(story['answer'][i])\n        starts.append(start)\n        ends.append(end)\n        i+=1\n    return{\n        'starts': starts,\n        'ends': ends\n    }\n    \nget_indexes(story)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:14.376594Z","iopub.execute_input":"2024-06-16T06:14:14.376882Z","iopub.status.idle":"2024-06-16T06:14:14.386547Z","shell.execute_reply.started":"2024-06-16T06:14:14.376858Z","shell.execute_reply":"2024-06-16T06:14:14.385622Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'starts': [24, 24, 24, 24, 20], 'ends': [31, 31, 31, 31, 27]}"},"metadata":{}}]},{"cell_type":"code","source":"processed = processed.map(get_indexes)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:14.387506Z","iopub.execute_input":"2024-06-16T06:14:14.387766Z","iopub.status.idle":"2024-06-16T06:14:15.124602Z","shell.execute_reply.started":"2024-06-16T06:14:14.387745Z","shell.execute_reply":"2024-06-16T06:14:15.123676Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01bd065f80f6494880a1c7f659930cca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e4387fbcdd49e48e790413d5d81d71"}},"metadata":{}}]},{"cell_type":"code","source":"processed['train'][2]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:15.128632Z","iopub.execute_input":"2024-06-16T06:14:15.129053Z","iopub.status.idle":"2024-06-16T06:14:15.137919Z","shell.execute_reply.started":"2024-06-16T06:14:15.129020Z","shell.execute_reply":"2024-06-16T06:14:15.137047Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'story.id': ['1',\n  '2',\n  '3',\n  '4',\n  '5',\n  '6',\n  '7',\n  '8',\n  '9',\n  '10',\n  '11',\n  '12',\n  '13',\n  '14',\n  '15'],\n 'story.type': [0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1],\n 'story.text': ['Mary went to the bedroom.',\n  'John journeyed to the bathroom.',\n  'Where is John?',\n  'Sandra journeyed to the hallway.',\n  'John journeyed to the garden.',\n  'Where is Mary?',\n  'John journeyed to the bathroom.',\n  'Sandra journeyed to the garden.',\n  'Where is John?',\n  'Sandra went back to the bedroom.',\n  'Daniel travelled to the bathroom.',\n  'Where is John?',\n  'John went to the office.',\n  'Mary moved to the office.',\n  'Where is Sandra?'],\n 'story.supporting_ids': [[],\n  [],\n  ['2'],\n  [],\n  [],\n  ['1'],\n  [],\n  [],\n  ['7'],\n  [],\n  [],\n  ['7'],\n  [],\n  [],\n  ['10']],\n 'story.answer': ['',\n  '',\n  'bathroom',\n  '',\n  '',\n  'bedroom',\n  '',\n  '',\n  'bathroom',\n  '',\n  '',\n  'bathroom',\n  '',\n  '',\n  'bedroom'],\n 'question': ['Where is John?',\n  'Where is Mary?',\n  'Where is John?',\n  'Where is John?',\n  'Where is Sandra?'],\n 'answer': ['bathroom', 'bedroom', 'bathroom', 'bathroom', 'bedroom'],\n 'sentences': 'Mary went to the bedroom. John journeyed to the bathroom. Sandra journeyed to the hallway. John journeyed to the garden. John journeyed to the bathroom. Sandra journeyed to the garden. Sandra went back to the bedroom. Daniel travelled to the bathroom. John went to the office. Mary moved to the office.',\n 'starts': [22, 17, 22, 22, 24],\n 'ends': [30, 24, 30, 30, 31]}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast\ntokenizer = DistilBertTokenizerFast.from_pretrained('/kaggle/input/tokeniser')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:15.138901Z","iopub.execute_input":"2024-06-16T06:14:15.139230Z","iopub.status.idle":"2024-06-16T06:14:19.070356Z","shell.execute_reply.started":"2024-06-16T06:14:15.139190Z","shell.execute_reply":"2024-06-16T06:14:19.069582Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def tokenize_align(example):\n    sentences = example['sentences']\n    questions = example['question']\n    \n    # Ensure sentences is a list of strings\n    if isinstance(sentences, list):\n        sentences = \" \".join(sentences)\n    elif not isinstance(sentences, str):\n        raise TypeError(\"The 'sentences' field must be a string or a list of strings.\")\n    \n\n    if isinstance(questions, list):\n        question = \" \".join(questions)\n    else:\n        raise TypeError(\"The 'question' field must be a list of strings.\")\n    \n    encoding = tokenizer(sentences, question, truncation=True, padding=True, max_length=tokenizer.model_max_length)\n    \n    start_positions = []\n    end_positions = []\n    \n    for start, end in zip(example['starts'], example['ends']):\n        start_pos = encoding.char_to_token(start)\n        end_pos = encoding.char_to_token(end - 1)\n        \n        if start_pos is None:\n            start_pos = tokenizer.model_max_length\n        if end_pos is None:\n            end_pos = tokenizer.model_max_length\n        \n        start_positions.append(start_pos)\n        end_positions.append(end_pos)\n    \n    return {\n        'input_ids': encoding['input_ids'],\n        'attention_mask': encoding['attention_mask'],\n        'start_positions': start_positions,\n        'end_positions': end_positions\n    }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:19.071446Z","iopub.execute_input":"2024-06-16T06:14:19.071911Z","iopub.status.idle":"2024-06-16T06:14:19.080771Z","shell.execute_reply.started":"2024-06-16T06:14:19.071887Z","shell.execute_reply":"2024-06-16T06:14:19.079823Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"qa_dataset= processed.map(tokenize_align)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:19.082106Z","iopub.execute_input":"2024-06-16T06:14:19.082907Z","iopub.status.idle":"2024-06-16T06:14:20.714273Z","shell.execute_reply.started":"2024-06-16T06:14:19.082883Z","shell.execute_reply":"2024-06-16T06:14:20.713270Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c62acc15c97d46bf8db11c5aec46b4ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e364ec7c40d433580d3ae760a57efd1"}},"metadata":{}}]},{"cell_type":"code","source":"qa_dataset = qa_dataset.remove_columns(['story.answer', 'story.id', 'story.supporting_ids', 'story.text', 'story.type'])","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:20.715333Z","iopub.execute_input":"2024-06-16T06:14:20.715617Z","iopub.status.idle":"2024-06-16T06:14:20.726045Z","shell.execute_reply.started":"2024-06-16T06:14:20.715593Z","shell.execute_reply":"2024-06-16T06:14:20.725192Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"qa_dataset['train'][200]","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:20.727487Z","iopub.execute_input":"2024-06-16T06:14:20.727954Z","iopub.status.idle":"2024-06-16T06:14:20.747650Z","shell.execute_reply.started":"2024-06-16T06:14:20.727924Z","shell.execute_reply":"2024-06-16T06:14:20.746751Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'question': ['Where is Mary?',\n  'Where is Sandra?',\n  'Where is Daniel?',\n  'Where is Daniel?',\n  'Where is John?'],\n 'answer': ['garden', 'garden', 'kitchen', 'bathroom', 'hallway'],\n 'sentences': 'Mary travelled to the garden. Daniel went to the kitchen. Sandra went back to the bathroom. Sandra moved to the garden. John travelled to the office. Mary journeyed to the kitchen. John went back to the bedroom. Daniel went back to the bathroom. John travelled to the bathroom. John journeyed to the hallway.',\n 'starts': [22, 20, 19, 24, 22],\n 'ends': [28, 26, 26, 32, 29],\n 'input_ids': [101,\n  2984,\n  7837,\n  2000,\n  1996,\n  3871,\n  1012,\n  3817,\n  2253,\n  2000,\n  1996,\n  3829,\n  1012,\n  12834,\n  2253,\n  2067,\n  2000,\n  1996,\n  5723,\n  1012,\n  12834,\n  2333,\n  2000,\n  1996,\n  3871,\n  1012,\n  2198,\n  7837,\n  2000,\n  1996,\n  2436,\n  1012,\n  2984,\n  4990,\n  2098,\n  2000,\n  1996,\n  3829,\n  1012,\n  2198,\n  2253,\n  2067,\n  2000,\n  1996,\n  5010,\n  1012,\n  3817,\n  2253,\n  2067,\n  2000,\n  1996,\n  5723,\n  1012,\n  2198,\n  7837,\n  2000,\n  1996,\n  5723,\n  1012,\n  2198,\n  4990,\n  2098,\n  2000,\n  1996,\n  6797,\n  1012,\n  102,\n  2073,\n  2003,\n  2984,\n  1029,\n  2073,\n  2003,\n  12834,\n  1029,\n  2073,\n  2003,\n  3817,\n  1029,\n  2073,\n  2003,\n  3817,\n  1029,\n  2073,\n  2003,\n  2198,\n  1029,\n  102],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1],\n 'start_positions': [5, 4, 4, 5, 5],\n 'end_positions': [5, 5, 5, 7, 6]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training ","metadata":{}},{"cell_type":"code","source":"train_ds = qa_dataset['train']\ntest_ds = qa_dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:20.748715Z","iopub.execute_input":"2024-06-16T06:14:20.749027Z","iopub.status.idle":"2024-06-16T06:14:20.757124Z","shell.execute_reply.started":"2024-06-16T06:14:20.748999Z","shell.execute_reply":"2024-06-16T06:14:20.756226Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import TFDistilBertForQuestionAnswering\nmodel = TFDistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\",return_dict=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:20.758135Z","iopub.execute_input":"2024-06-16T06:14:20.758417Z","iopub.status.idle":"2024-06-16T06:14:35.345119Z","shell.execute_reply.started":"2024-06-16T06:14:20.758373Z","shell.execute_reply":"2024-06-16T06:14:35.344352Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2024-06-16 06:14:22.571663: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-16 06:14:22.571764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-16 06:14:22.711804: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16cb205fd5f4cb398a1d9be26748bf7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97e8294d917d4841b5ae75d0ec3be524"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForQuestionAnswering: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n- This IS expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_ds['start_positions'][0])  # Should print the first element in the list\nprint(train_ds['end_positions'][0]) ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:35.346107Z","iopub.execute_input":"2024-06-16T06:14:35.346359Z","iopub.status.idle":"2024-06-16T06:14:35.666250Z","shell.execute_reply.started":"2024-06-16T06:14:35.346337Z","shell.execute_reply":"2024-06-16T06:14:35.665340Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[5, 5, 5, 5, 5]\n[5, 7, 7, 7, 7]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_ds.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:14:35.668707Z","iopub.execute_input":"2024-06-16T06:14:35.668987Z","iopub.status.idle":"2024-06-16T06:14:35.674536Z","shell.execute_reply.started":"2024-06-16T06:14:35.668963Z","shell.execute_reply":"2024-06-16T06:14:35.673658Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(2000, 9)"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\n\ncolumns_to_return = ['input_ids','attention_mask', 'start_positions', 'end_positions']\n\ntrain_ds.set_format(type='tensorflow', columns=columns_to_return)\n\nstart_positions = [tf.convert_to_tensor(train_ds['start_positions'][i],dtype=tf.int64) for i in range(len(train_ds['start_positions']))]\nend_positions = [tf.convert_to_tensor(train_ds['end_positions'][i],dtype=tf.int64) for i in range(len(train_ds['end_positions']))]\n\n\n# train_features = {x: train_ds[x] for x in ['input_ids', 'attention_mask']}\n# train_labels = {\"start_positions\": start_positions, \"end_positions\": end_positions}\n\n# train_tfdataset = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).batch(8)\nprint(type(start_positions))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:18:45.283806Z","iopub.execute_input":"2024-06-16T06:18:45.284150Z","iopub.status.idle":"2024-06-16T06:19:03.234623Z","shell.execute_reply.started":"2024-06-16T06:18:45.284122Z","shell.execute_reply":"2024-06-16T06:19:03.233684Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(start_positions[0]))\nprint(tf.shape(start_positions))\nprint(start_positions[0])\nprint(type(train_ds['start_positions'][0]))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:19:55.707297Z","iopub.execute_input":"2024-06-16T06:19:55.707909Z","iopub.status.idle":"2024-06-16T06:19:55.723072Z","shell.execute_reply.started":"2024-06-16T06:19:55.707878Z","shell.execute_reply":"2024-06-16T06:19:55.722231Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"<class 'tensorflow.python.framework.ops.EagerTensor'>\ntf.Tensor([2000    5], shape=(2,), dtype=int32)\ntf.Tensor([5 5 5 5 5], shape=(5,), dtype=int64)\n<class 'tensorflow.python.framework.ops.EagerTensor'>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(type(train_ds['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T06:21:30.430061Z","iopub.execute_input":"2024-06-16T06:21:30.430437Z","iopub.status.idle":"2024-06-16T06:21:31.410897Z","shell.execute_reply.started":"2024-06-16T06:21:30.430383Z","shell.execute_reply":"2024-06-16T06:21:31.409972Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"<class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming your model definition and dataset setup are already done\n\nEPOCHS = 3\nloss_fn1 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nloss_fn2 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\nopt = tf.keras.optimizers.Adam(learning_rate=3e-5)\n\nlosses = []\nfor epoch in range(EPOCHS):\n    print(\"Starting epoch: %d\" % epoch)\n    for step, (x_batch_train, y_batch_train) in enumerate(train_tfdataset):\n        # Convert necessary inputs to TensorFlow tensors if they are not already\n        x_batch_train['input_ids'] = tf.convert_to_tensor(x_batch_train['input_ids'])\n        x_batch_train['attention_mask'] = tf.convert_to_tensor(x_batch_train['attention_mask'])\n\n        # Handle ragged tensors (if any)\n        y_batch_train['start_positions'] = tf.RaggedTensor.from_tensor(y_batch_train['start_positions'])\n        y_batch_train['end_positions'] = tf.RaggedTensor.from_tensor(y_batch_train['end_positions'])\n\n        with tf.GradientTape() as tape:\n            answer_start_scores, answer_end_scores = model(x_batch_train)\n            \n            # Convert model outputs to dense tensors if necessary\n            answer_start_scores = tf.convert_to_tensor(answer_start_scores)\n            answer_end_scores = tf.convert_to_tensor(answer_end_scores)\n\n            # Calculate losses\n            loss_start = loss_fn1(y_batch_train['start_positions'].to_tensor(), answer_start_scores)\n            loss_end = loss_fn2(y_batch_train['end_positions'].to_tensor(), answer_end_scores)\n            loss = 0.5 * (loss_start + loss_end)\n        \n        losses.append(loss)\n        grads = tape.gradient(loss, model.trainable_weights)\n        opt.apply_gradients(zip(grads, model.trainable_weights))\n\n        if step % 20 == 0:\n            print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss_start)))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T17:47:06.477191Z","iopub.execute_input":"2024-06-15T17:47:06.477566Z","iopub.status.idle":"2024-06-15T17:47:06.566764Z","shell.execute_reply.started":"2024-06-15T17:47:06.477534Z","shell.execute_reply":"2024-06-15T17:47:06.565660Z"},"trusted":true},"execution_count":125,"outputs":[{"name":"stdout","text":"Starting epoch: 0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[125], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting epoch: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m epoch)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x_batch_train, y_batch_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_tfdataset):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Convert necessary inputs to TensorFlow tensors if they are not already\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     x_batch_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     x_batch_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x_batch_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Handle ragged tensors (if any)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'RaggedTensor' has no len()\n"],"ename":"ValueError","evalue":"TypeError: object of type 'RaggedTensor' has no len()\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}