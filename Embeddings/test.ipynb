{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_vectors(glove_path):\n",
    "    with open(glove_path, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            current_word = line[0]\n",
    "            words.add(current_word)\n",
    "            word_to_vec[current_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "    return words,word_to_vec\n",
    "\n",
    "words , word_map = get_vectors('/home/yash/DeepLearning/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Word Vectors\n",
    "\n",
    "Here we use a 6B word count corpus with each word having a vector of 50 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      " -1.1514e-01 -7.8581e-01]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "print(word_map['the']) # Embeddings for the word\n",
    "print(len(word_map['the'])) # Dimensions of each word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8909038442893615\n",
      "0.9218005273769252\n",
      "0.27439246261379424\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(u,v):\n",
    "    if np.all(u == v):\n",
    "        return 1\n",
    "    \n",
    "    dot = np.dot(u,v)\n",
    "\n",
    "    norm_u = np.sqrt(np.sum(u ** 2))\n",
    "    norm_v = np.sqrt(np.sum(v ** 2))\n",
    "\n",
    "    if np.isclose(norm_u * norm_v,0,atol=1e-32):\n",
    "        return 0 \n",
    "    \n",
    "    return dot / (norm_u * norm_v)\n",
    "\n",
    "\n",
    "print(cosine_similarity(word_map['father'],word_map['mother']))\n",
    "print(cosine_similarity(word_map['dog'],word_map['cat']))\n",
    "print(cosine_similarity(word_map['ball'],word_map['crocodile']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see here that the analogy for some words is not correct. This is due to the lack of learn't embeddings and also the small dimension of the word embeddings. Which restricts the model to only learn the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smaller\n",
      "spanish\n"
     ]
    }
   ],
   "source": [
    "def get_analogy(a: str,b: str,c: str,word_map: dict) -> str:\n",
    "    a , b , c = a.lower(),b.lower(), c.lower()\n",
    "\n",
    "    e_a, e_b , e_c = word_map[a],word_map[b],word_map[c]\n",
    "\n",
    "    words = word_map.keys()\n",
    "    max_cosine = -100\n",
    "    best_word = None\n",
    "\n",
    "    for w in words:\n",
    "        if w == c:\n",
    "            continue\n",
    "\n",
    "        similarity = cosine_similarity(e_b-e_a,word_map[w]-e_c)\n",
    "\n",
    "        if similarity > max_cosine:\n",
    "            max_cosine = similarity\n",
    "            best_word = w\n",
    "\n",
    "    return best_word\n",
    "\n",
    "\n",
    "print(get_analogy('small','smaller','large',word_map))\n",
    "print(get_analogy('italy','italian','spain',word_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing the word embeddings (Mostly gender bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.087144    0.2182     -0.40986    -0.03922    -0.1032      0.94165\n",
      " -0.06042     0.32988     0.46144    -0.35962     0.31102    -0.86824\n",
      "  0.96006     0.01073     0.24337     0.08193    -1.02722    -0.21122\n",
      "  0.695044   -0.00222     0.29106     0.5053     -0.099454    0.40445\n",
      "  0.30181     0.1355     -0.0606     -0.07131    -0.19245    -0.06115\n",
      " -0.3204      0.07165    -0.13337    -0.25068714 -0.14293    -0.224957\n",
      " -0.149       0.048882    0.12191    -0.27362    -0.165476   -0.20426\n",
      "  0.54376    -0.271425   -0.10245    -0.32108     0.2516     -0.33455\n",
      " -0.04371     0.01258   ]\n"
     ]
    }
   ],
   "source": [
    "# Some biases in the embeddings\n",
    "g = word_map['woman'] - word_map['man']\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john -0.23163356145973724\n",
      "marie 0.31559793539607295\n",
      "sophie 0.31868789859418784\n",
      "ronaldo -0.3124479685032943\n",
      "priya 0.17632041839009407\n",
      "rahul -0.16915471039231722\n",
      "danielle 0.24393299216283892\n",
      "reza -0.0793042967219955\n",
      "katy 0.2831068659572615\n",
      "yasmin 0.23313857767928753\n"
     ]
    }
   ],
   "source": [
    "# No bias\n",
    "name_list = ['john', 'marie', 'sophie', 'ronaldo', 'priya', 'rahul', 'danielle', 'reza', 'katy', 'yasmin']\n",
    "\n",
    "for w in name_list:\n",
    "    print (w, cosine_similarity(word_map[w], g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer -0.10330358873850494\n",
      "scientist -0.0519303528131346\n",
      "engineer -0.08039280494524072\n",
      "doctor 0.1189528941093504\n",
      "lawyer 0.019827378154494146\n"
     ]
    }
   ],
   "source": [
    "# Gender bias\n",
    "words = ['computer','scientist','engineer','doctor','lawyer']\n",
    "for word in words:\n",
    "    print(word, cosine_similarity(word_map[word],g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that the occupations have a negative value which are also close to the male embeddings found above. \n",
    "This proves  that the embeddings have a bias. \n",
    "We need to fix this bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
